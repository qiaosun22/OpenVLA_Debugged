# OpenVLA å¿«é€Ÿå‚è€ƒå¡ç‰‡

> ğŸš€ å¿«é€Ÿå‘½ä»¤å’Œä»£ç ç‰‡æ®µï¼Œéšæ—¶å¯ç”¨

## ç¯å¢ƒæ¿€æ´»

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate openvla

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¸€æ¬¡æ€§ï¼‰
export MUJOCO_GL=osmesa
export PYOPENGL_PLATFORM=osmesa
export PYTHONPATH="/robot/robot-rfm/user/qiao/code/openvla/LIBERO:${PYTHONPATH}"
```

## éªŒè¯æµ‹è¯•

```bash
# å¿«é€ŸéªŒè¯ï¼ˆ30ç§’ï¼‰
python /robot/robot-rfm/user/qiao/verify_openvla.py

# å®Œæ•´æµ‹è¯•ï¼ˆ2åˆ†é’Ÿï¼ŒåŒ…å«æ¨¡å‹åŠ è½½ï¼‰
python /robot/robot-rfm/user/qiao/quick_test_openvla_safe.py
```

## ä»£ç æ¨¡æ¿

### åŸºç¡€ä½¿ç”¨æ¨¡æ¿

```python
import os, sys, torch
import numpy as np
from PIL import Image
from transformers import AutoModelForVision2Seq, AutoProcessor

# ç¯å¢ƒè®¾ç½®
os.environ["MUJOCO_GL"] = "osmesa"
os.environ["PYOPENGL_PLATFORM"] = "osmesa"
sys.path.insert(0, "/robot/robot-rfm/user/qiao/code/openvla/LIBERO")

# åŠ è½½æ¨¡å‹
model_path = "/robot/robot-rfm/user/qiao/tmp/.hf_cache/hub/openvla"
processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True, local_files_only=True)
vla = AutoModelForVision2Seq.from_pretrained(
    model_path,
    torch_dtype=torch.float16,  # â† é‡è¦ï¼ç”¨ float16
    local_files_only=True,
    low_cpu_mem_usage=True,
    trust_remote_code=True
).to("cuda:0")

# é¢„æµ‹åŠ¨ä½œ
image = Image.open("image.jpg").convert("RGB")
prompt = "In: What action should the robot take to pick up the object?\nOut:"
inputs = processor(prompt, image).to("cuda:0", dtype=torch.float16)  # â† é‡è¦ï¼ç”¨ float16
action = vla.predict_action(**inputs, unnorm_key="bridge_orig", do_sample=False)
print(f"Action: {action}")  # 7-DoF: [x, y, z, rx, ry, rz, gripper]
```

### LIBERO ç¯å¢ƒæ¨¡æ¿

```python
from libero.libero import benchmark, get_libero_path
from libero.libero.envs import OffScreenRenderEnv
import os

# åŠ è½½ä»»åŠ¡
task_suite = benchmark.get_benchmark_dict()["libero_object"]()
task = task_suite.get_task(0)

# åˆ›å»ºç¯å¢ƒ
env = OffScreenRenderEnv(
    bddl_file_name=os.path.join(get_libero_path("bddl_files"), task.problem_folder, task.bddl_file),
    camera_heights=512,
    camera_widths=512,
    camera_names=["agentview", "sideview"],
)

# è¿è¡Œ
env.reset()
obs, reward, done, info = env.step([0.0] * 7)
image = obs["agentview_image"]
```

### å›¾åƒå¤„ç†è¾…åŠ©å‡½æ•°

```python
def ensure_pil_image(img):
    """ç¡®ä¿å›¾åƒæ˜¯ PIL Image æ ¼å¼"""
    from PIL import Image
    import numpy as np

    if isinstance(img, Image.Image):
        return img.convert("RGB")
    elif isinstance(img, np.ndarray):
        if img.ndim == 2:
            img = np.stack([img] * 3, axis=-1)
        elif img.shape[-1] == 4:
            img = img[:, :, :3]
        if img.dtype != np.uint8:
            img = (img * 255).astype(np.uint8) if img.max() <= 1.0 else img.astype(np.uint8)
        return Image.fromarray(img).convert("RGB")
    raise TypeError(f"Unsupported image type: {type(img)}")
```

## å¸¸è§é”™è¯¯é€Ÿè§£

| é”™è¯¯ | è§£å†³æ–¹æ¡ˆ |
|------|---------|
| `Floating point exception` | æ”¹ç”¨ `torch.float16`ï¼ˆä¸æ˜¯ `bfloat16`ï¼‰ |
| `ModuleNotFoundError: libero` | `export PYTHONPATH="/robot/robot-rfm/user/qiao/code/openvla/LIBERO:${PYTHONPATH}"` |
| `CUDA out of memory` | æ·»åŠ  `low_cpu_mem_usage=True` |
| äº¤äº’å¼è·¯å¾„æç¤º | åˆ›å»º `~/.libero/config.yaml` |

## å…³é”®è·¯å¾„é€ŸæŸ¥

| è·¯å¾„ | è¯´æ˜ |
|------|------|
| `/robot/robot-rfm/user/qiao/code/openvla` | ä»£ç ç›®å½• |
| `/robot/robot-rfm/user/qiao/tmp/.hf_cache/hub/openvla` | æ¨¡å‹æ–‡ä»¶ |
| `/robot/robot-rfm/user/qiao/code/openvla/LIBERO` | LIBERO ç¯å¢ƒ |
| `~/.libero/config.yaml` | LIBERO é…ç½® |
| `/robot/robot-rfm/user/qiao/verify_openvla.py` | éªŒè¯è„šæœ¬ |

## é‡è¦æé†’ âš ï¸

1. **å¿…é¡»ä½¿ç”¨ `torch.float16`**ï¼Œä¸èƒ½ç”¨ `torch.bfloat16`ï¼ˆH20 GPU å…¼å®¹æ€§é—®é¢˜ï¼‰
2. **æ¨¡å‹åŠ è½½éœ€è¦ 2-3 åˆ†é’Ÿ**ï¼Œè¯·è€å¿ƒç­‰å¾…
3. **é¦–æ¬¡ä½¿ç”¨ LIBERO éœ€è¦åˆ›å»ºé…ç½®æ–‡ä»¶**ï¼ˆè§ä¸Šæ–¹å¸¸è§é”™è¯¯ï¼‰
4. **æ— å¤´ç¯å¢ƒå¿…é¡»è®¾ç½® `MUJOCO_GL=osmesa`**

## ä¸€é”®å¯åŠ¨ Jupyter

```bash
cd /robot/robot-rfm/user/qiao/code/openvla
conda activate openvla
export MUJOCO_GL=osmesa
export PYOPENGL_PLATFORM=osmesa
export PYTHONPATH="/robot/robot-rfm/user/qiao/code/openvla/LIBERO:${PYTHONPATH}"
jupyter notebook --no-browser --port=8888
```

---
ğŸ’¡ å®Œæ•´æ–‡æ¡£è¯·å‚é˜… `README_GET_STARTED.md`
