# OpenVLA å¿«é€Ÿå…¥é—¨æŒ‡å—

> æœ€åŽæ›´æ–°ï¼š2026-02-26
> æµ‹è¯•çŽ¯å¢ƒï¼šNVIDIA H20-3e, CUDA 12.1

## ðŸ“‹ ç›®å½•

- [çŽ¯å¢ƒæ¦‚è¿°](#çŽ¯å¢ƒæ¦‚è¿°)
- [çŽ¯å¢ƒè¦æ±‚](#çŽ¯å¢ƒè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [çŽ¯å¢ƒé…ç½®](#çŽ¯å¢ƒé…ç½®)
- [éªŒè¯æµ‹è¯•](#éªŒè¯æµ‹è¯•)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [é¡¹ç›®ç»“æž„](#é¡¹ç›®ç»“æž„)

---

## çŽ¯å¢ƒæ¦‚è¿°

æœ¬é¡¹ç›®åŒ…å«ä»¥ä¸‹æ ¸å¿ƒç»„ä»¶ï¼š

- **OpenVLA**: å¼€æºè§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡åž‹
- **LIBERO**: æœºå™¨äººæ“ä½œæ¨¡æ‹ŸçŽ¯å¢ƒ
- **Conda çŽ¯å¢ƒ**: `openvla`

**çŽ¯å¢ƒè·¯å¾„**ï¼š
- ä»£ç ç›®å½•ï¼š`/robot/robot-rfm/user/qiao/code/openvla`
- æ¨¡åž‹ç¼“å­˜ï¼š`/robot/robot-rfm/user/qiao/tmp/.hf_cache/hub/openvla`

---

## çŽ¯å¢ƒè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- GPUï¼šNVIDIA H20 æˆ–å…¼å®¹ CUDA çš„æ˜¾å¡ï¼ˆå»ºè®® 16GB+ æ˜¾å­˜ï¼‰
- å†…å­˜ï¼šå»ºè®® 32GB+
- ç£ç›˜ï¼šè‡³å°‘ 50GB å¯ç”¨ç©ºé—´

### è½¯ä»¶ä¾èµ–
- Python 3.10
- CUDA 12.1
- Conda/Miniconda

---

## å¿«é€Ÿå¼€å§‹

### 1. æ¿€æ´» Conda çŽ¯å¢ƒ

```bash
conda activate openvla
```

### 2. è®¾ç½®å¿…è¦çš„çŽ¯å¢ƒå˜é‡

```bash
# è®¾ç½®æ¸²æŸ“åŽç«¯ï¼ˆæ— å¤´çŽ¯å¢ƒå¿…éœ€ï¼‰
export MUJOCO_GL=osmesa
export PYOPENGL_PLATFORM=osmesa

# è®¾ç½® LIBERO è·¯å¾„
export PYTHONPATH="/robot/robot-rfm/user/qiao/code/openvla/LIBERO:${PYTHONPATH}"
```

### 3. è¿è¡ŒéªŒè¯è„šæœ¬

```bash
# å®Œæ•´çŽ¯å¢ƒéªŒè¯
python /robot/robot-rfm/user/qiao/verify_openvla.py

# æ¨¡åž‹åŠ è½½å’Œé¢„æµ‹æµ‹è¯•
python /robot/robot-rfm/user/qiao/quick_test_openvla_safe.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ“ All tests passed! Your OpenVLA environment is ready.
```

---

## çŽ¯å¢ƒé…ç½®

### LIBERO é…ç½®

LIBERO éœ€è¦é…ç½®æ–‡ä»¶æ¥é¿å…äº¤äº’å¼æç¤ºã€‚é…ç½®æ–‡ä»¶ä½äºŽ `~/.libero/config.yaml`ï¼š

```yaml
benchmark_root: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero
bddl_files: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero/bddl_files
init_states: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero/init_files
datasets: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/datasets
assets: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero/assets
```

å¦‚æžœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤åˆ›å»ºï¼š

```bash
cat > ~/.libero/config.yaml << 'EOF'
benchmark_root: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero
bddl_files: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero/bddl_files
init_states: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero/init_files
datasets: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/datasets
assets: /robot/robot-rfm/user/qiao/code/openvla/LIBERO/libero/libero/assets
EOF
```

### æ°¸ä¹…è®¾ç½®çŽ¯å¢ƒå˜é‡

å°†ä»¥ä¸‹å†…å®¹æ·»åŠ åˆ°ä½ çš„ `~/.bashrc` æˆ– `~/.zshrc`ï¼š

```bash
# OpenVLA & LIBERO çŽ¯å¢ƒå˜é‡
export MUJOCO_GL=osmesa
export PYOPENGL_PLATFORM=osmesa
export PYTHONPATH="/robot/robot-rfm/user/qiao/code/openvla/LIBERO:${PYTHONPATH}"
```

ç„¶åŽæ‰§è¡Œï¼š
```bash
source ~/.bashrc  # æˆ– source ~/.zshrc
```

---

## éªŒè¯æµ‹è¯•

### è‡ªåŠ¨éªŒè¯è„šæœ¬

æˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªéªŒè¯è„šæœ¬ï¼š

#### 1. çŽ¯å¢ƒéªŒè¯ (`verify_openvla.py`)

æµ‹è¯•é¡¹ç›®ï¼š
- âœ“ Python ä¾èµ–åŒ… (numpy, PIL, torch, transformers, libero)
- âœ“ OpenVLA æ¨¡åž‹æ–‡ä»¶å­˜åœ¨æ€§
- âœ“ Processor åŠ è½½
- âœ“ LIBERO çŽ¯å¢ƒåŠ è½½
- âœ“ Replay ç›®å½•æ£€æŸ¥

è¿è¡Œæ–¹å¼ï¼š
```bash
conda run -n openvla python /robot/robot-rfm/user/qiao/verify_openvla.py
```

#### 2. æ¨¡åž‹æµ‹è¯• (`quick_test_openvla_safe.py`)

æµ‹è¯•é¡¹ç›®ï¼š
- âœ“ CUDA å¯ç”¨æ€§
- âœ“ Processor åŠ è½½
- âœ“ æ¨¡åž‹åŠ è½½ï¼ˆä½¿ç”¨ float16ï¼‰
- âœ“ åŠ¨ä½œé¢„æµ‹åŠŸèƒ½

è¿è¡Œæ–¹å¼ï¼š
```bash
conda run -n openvla python /robot/robot-rfm/user/qiao/quick_test_openvla_safe.py
```

é¢„æœŸè¾“å‡ºç¤ºä¾‹ï¼š
```
[Test 1] CUDA Check
  CUDA available: True
  CUDA device: NVIDIA H20-3e

[Test 2] Loading Processor...
  âœ“ Processor loaded successfully

[Test 3] Loading OpenVLA Model...
  âœ“ Model loaded successfully with float16
  Model device: cuda:0
  Model dtype: torch.float16

[Test 4] Testing Action Prediction...
  âœ“ Action predicted successfully
    - Action shape: (7,)
    - Action values: [-0.00289288 -0.00592804  0.02054478 ...]
```

---

## ä½¿ç”¨ç¤ºä¾‹

### Python è„šæœ¬ä½¿ç”¨

```python
import os
import sys
import torch
import numpy as np
from PIL import Image
from transformers import AutoModelForVision2Seq, AutoProcessor

# 1. è®¾ç½®çŽ¯å¢ƒå˜é‡
os.environ["MUJOCO_GL"] = "osmesa"
os.environ["PYOPENGL_PLATFORM"] = "osmesa"
sys.path.insert(0, "/robot/robot-rfm/user/qiao/code/openvla/LIBERO")

# 2. åŠ è½½æ¨¡åž‹
model_path = "/robot/robot-rfm/user/qiao/tmp/.hf_cache/hub/openvla"
processor = AutoProcessor.from_pretrained(
    model_path,
    trust_remote_code=True,
    local_files_only=True,
)

vla = AutoModelForVision2Seq.from_pretrained(
    model_path,
    torch_dtype=torch.float16,  # é‡è¦ï¼šä½¿ç”¨ float16 è€Œéž bfloat16
    local_files_only=True,
    low_cpu_mem_usage=True,
    trust_remote_code=True
).to("cuda:0")

# 3. å‡†å¤‡è¾“å…¥
image = Image.open("your_image.jpg").convert("RGB")
prompt = "In: What action should the robot take to pick up the apple?\nOut:"

# 4. é¢„æµ‹åŠ¨ä½œ
inputs = processor(prompt, image).to("cuda:0", dtype=torch.float16)
action = vla.predict_action(**inputs, unnorm_key="bridge_orig", do_sample=False)

print(f"Predicted action: {action}")  # 7-DoF robot action
```

### Jupyter Notebook ä½¿ç”¨

ä½¿ç”¨ `dev.ipynb` è¿›è¡Œäº¤äº’å¼å¼€å‘ï¼š

```bash
cd /robot/robot-rfm/user/qiao/code/openvla
conda activate openvla
jupyter notebook
```

**é‡è¦ä¿®æ”¹**ï¼šåœ¨ `dev.ipynb` ä¸­ï¼Œå°†æ‰€æœ‰ `torch.bfloat16` æ›¿æ¢ä¸º `torch.float16`ï¼š

```python
# ä¿®æ”¹å‰ï¼ˆä¼šå¯¼è‡´æµ®ç‚¹å¼‚å¸¸ï¼‰ï¼š
vla = AutoModelForVision2Seq.from_pretrained(
    model_path,
    torch_dtype=torch.bfloat16,  # âŒ
    ...
)
inputs = processor(prompt, image).to("cuda:0", dtype=torch.bfloat16)  # âŒ

# ä¿®æ”¹åŽï¼ˆæ­£å¸¸å·¥ä½œï¼‰ï¼š
vla = AutoModelForVision2Seq.from_pretrained(
    model_path,
    torch_dtype=torch.float16,  # âœ“
    ...
)
inputs = processor(prompt, image).to("cuda:0", dtype=torch.float16)  # âœ“
```

### LIBERO çŽ¯å¢ƒä½¿ç”¨

```python
from libero.libero import benchmark, get_libero_path
from libero.libero.envs import OffScreenRenderEnv

# èŽ·å–ä»»åŠ¡
benchmark_dict = benchmark.get_benchmark_dict()
task_suite = benchmark_dict["libero_object"]()
task = task_suite.get_task(0)

print(f"Task: {task.name}")
print(f"Description: {task.language}")

# åˆ›å»ºçŽ¯å¢ƒ
bddl_file = os.path.join(get_libero_path("bddl_files"), task.problem_folder, task.bddl_file)
env = OffScreenRenderEnv(
    bddl_file_name=bddl_file,
    camera_heights=512,
    camera_widths=512,
    camera_names=["agentview", "sideview"],
)

# é‡ç½®çŽ¯å¢ƒ
env.reset()
obs, reward, done, info = env.step([0.0] * 7)

# èŽ·å–å›¾åƒ
agentview_img = obs["agentview_image"]
sideview_img = obs["sideview_image"]
```

---

## å¸¸è§é—®é¢˜

### Q1: æµ®ç‚¹å¼‚å¸¸ (Floating point exception)

**é—®é¢˜**ï¼šåŠ è½½æ¨¡åž‹æ—¶å‡ºçŽ° `Floating point exception`

**åŽŸå› **ï¼šæŸäº› GPUï¼ˆå¦‚ H20ï¼‰ä¸Ž `torch.bfloat16` ä¸å…¼å®¹

**è§£å†³**ï¼šä½¿ç”¨ `torch.float16` ä»£æ›¿ `torch.bfloat16`

```python
# é”™è¯¯
torch_dtype=torch.bfloat16

# æ­£ç¡®
torch_dtype=torch.float16
```

### Q2: LIBERO å¯¼å…¥é”™è¯¯

**é—®é¢˜**ï¼š`ModuleNotFoundError: No module named 'libero'`

**åŽŸå› **ï¼šLIBERO ä¸åœ¨ PYTHONPATH ä¸­

**è§£å†³**ï¼š
```bash
export PYTHONPATH="/robot/robot-rfm/user/qiao/code/openvla/LIBERO:${PYTHONPATH}"
```

### Q3: LIBERO äº¤äº’å¼æç¤º

**é—®é¢˜**ï¼šå¯¼å…¥ LIBERO æ—¶å‡ºçŽ° `Do you want to specify a custom path...` æç¤º

**åŽŸå› **ï¼šç¼ºå°‘ LIBERO é…ç½®æ–‡ä»¶

**è§£å†³**ï¼šåˆ›å»º `~/.libero/config.yaml` æ–‡ä»¶ï¼ˆè§ [çŽ¯å¢ƒé…ç½®](#çŽ¯å¢ƒé…ç½®)ï¼‰

### Q4: CUDA å†…å­˜ä¸è¶³

**é—®é¢˜**ï¼š`CUDA out of memory`

**è§£å†³**ï¼š
```python
# æ–¹æ¡ˆ 1ï¼šä½¿ç”¨ low_cpu_mem_usage=True
vla = AutoModelForVision2Seq.from_pretrained(
    model_path,
    low_cpu_mem_usage=True,
    ...
)

# æ–¹æ¡ˆ 2ï¼šå‡å°æ‰¹å¤„ç†å¤§å°
# æ–¹æ¡ˆ 3ï¼šä½¿ç”¨æ›´å°çš„æ¨¡åž‹å˜ä½“
```

### Q5: å›¾åƒæ ¼å¼é”™è¯¯

**é—®é¢˜**ï¼šå›¾åƒå¤„ç†æ—¶å‡ºçŽ°ç»´åº¦æˆ–æ ¼å¼é”™è¯¯

**è§£å†³**ï¼šä½¿ç”¨è¾…åŠ©å‡½æ•°ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®

```python
def ensure_pil_image(img):
    from PIL import Image
    import numpy as np

    if isinstance(img, Image.Image):
        return img.convert("RGB")
    elif isinstance(img, np.ndarray):
        if img.ndim == 2:
            img = np.stack([img] * 3, axis=-1)
        elif img.shape[-1] == 4:
            img = img[:, :, :3]
        if img.dtype != np.uint8:
            img = (img * 255).astype(np.uint8) if img.max() <= 1.0 else img.astype(np.uint8)
        return Image.fromarray(img).convert("RGB")
    else:
        raise TypeError(f"Unsupported image type: {type(img)}")

# ä½¿ç”¨
image = ensure_pil_image(your_image)
```

---

## é¡¹ç›®ç»“æž„

```
/robot/robot-rfm/user/qiao/code/openvla/
â”œâ”€â”€ LIBERO/                          # LIBERO æ¨¡æ‹ŸçŽ¯å¢ƒ
â”‚   â””â”€â”€ libero/                      # LIBERO æ ¸å¿ƒä»£ç 
â”‚       â”œâ”€â”€ libero/                  # libero åŒ…
â”‚       â”‚   â”œâ”€â”€ benchmark/           # åŸºå‡†æµ‹è¯•
â”‚       â”‚   â”œâ”€â”€ bddl_files/          # ä»»åŠ¡æè¿°æ–‡ä»¶
â”‚       â”‚   â”œâ”€â”€ envs/                # çŽ¯å¢ƒå®šä¹‰
â”‚       â”‚   â””â”€â”€ utils/               # å·¥å…·å‡½æ•°
â”‚       â””â”€â”€ configs/                 # é…ç½®æ–‡ä»¶
â”œâ”€â”€ libero_replay_20/                # å›žæ”¾æ•°æ®
â”‚   â””â”€â”€ libero_object__1__.../
â”‚       â””â”€â”€ camera_calib.json        # ç›¸æœºæ ‡å®šæ–‡ä»¶
â”œâ”€â”€ dev.ipynb                        # å¼€å‘ notebookï¼ˆéœ€è¦ä¿®æ”¹ dtypeï¼‰
â”œâ”€â”€ rollouts_1231/                   # ç”Ÿæˆè½¨è¿¹è¾“å‡º
â””â”€â”€ README_GET_STARTED.md            # æœ¬æ–‡ä»¶

éªŒè¯è„šæœ¬ä½ç½®ï¼š
â”œâ”€â”€ /robot/robot-rfm/user/qiao/verify_openvla.py              # çŽ¯å¢ƒéªŒè¯
â””â”€â”€ /robot/robot-rfm/user/qiao/quick_test_openvla_safe.py     # æ¨¡åž‹æµ‹è¯•

æ¨¡åž‹æ–‡ä»¶ä½ç½®ï¼š
â””â”€â”€ /robot/robot-rfm/user/qiao/tmp/.hf_cache/hub/openvla/     # OpenVLA æ¨¡åž‹
```

---

## ç‰ˆæœ¬ä¿¡æ¯

æµ‹è¯•é€šè¿‡çš„çŽ¯å¢ƒç‰ˆæœ¬ï¼š

| åŒ… | ç‰ˆæœ¬ |
|---|------|
| Python | 3.10 |
| PyTorch | 2.2.0+cu121 |
| Transformers | 4.40.1 |
| NumPy | 1.26.4 |
| Pillow | 12.0.0 |
| CUDA | 12.1 |
| GPU | NVIDIA H20-3e |

---

## ä¸‹ä¸€æ­¥

- ðŸ“– é˜…è¯» [OpenVLA å®˜æ–¹æ–‡æ¡£](https://github.com/openvla/openvla)
- ðŸŽ® å°è¯•ä¸åŒçš„ LIBERO ä»»åŠ¡
- ðŸ¤– è®­ç»ƒè‡ªå®šä¹‰æ¨¡åž‹
- ðŸ“Š åˆ†æžå’Œå¯è§†åŒ–æ¨¡åž‹è¾“å‡º

---

## å‚è€ƒèµ„æº

- [OpenVLA GitHub](https://github.com/openvla/openvla)
- [LIBERO æ–‡æ¡£](https://libero-project.github.io/)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

---

**ç»´æŠ¤è€…**: qiao
**æœ€åŽæ›´æ–°**: 2026-02-26
